{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go through basics of Convolutional neural nets for NLP. We follow the book \"Natural Language Processing in Action\" by H. Lane, C. Howard, H.M. Hapke\n",
    "\n",
    "\"Language’s true power isn’t in the words themselves, but in the spaces between the words, in the order and combination of words. Sometimes meaning is hidden beneath the words, in the intent and emotion that formed that particular combination of words.\"\n",
    "\n",
    "Basic feedforward networks are capable of pulling patterns out of data. But, the patterns they discover are found by relating weights to pieces of the input. Nothing captures the relations of the tokens. The one of most important neural network architectures for natural language processing is convolutional neural nets. It captures the relations of the tokens spatially.\n",
    "\n",
    "$ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pugnlp/constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pugnlp/constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import glob\n",
    "import re\n",
    "import tqdm\n",
    "\n",
    "import requests\n",
    "from pugnlp.futil import path_status, find_files\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pugnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def pre_process_data(filepath):\n",
    "    dataset = []\n",
    "    \n",
    "    true=pd.read_csv(os.path.join(filepath, 'True.csv'))\n",
    "    true['target']=0\n",
    "    fake=pd.read_csv(os.path.join(filepath, 'Fake.csv'))\n",
    "    fake['target']=1\n",
    "    \n",
    "    dataset=pd.concat([true,fake],join='outer',axis=0)\n",
    "    dataset=shuffle(dataset, random_state=42)\n",
    "    dataset=dataset.reset_index(drop=True)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pre_process_data('/Users/taronzakaryan/input/fake_and_real_news_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREAKING: GOP Chairman Grassley Has Had Enoug...</td>\n",
       "      <td>Donald Trump s White House is in chaos, and th...</td>\n",
       "      <td>News</td>\n",
       "      <td>July 21, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Failed GOP Candidates Remembered In Hilarious...</td>\n",
       "      <td>Now that Donald Trump is the presumptive GOP n...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 7, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike Pence’s New DC Neighbors Are HILARIOUSLY...</td>\n",
       "      <td>Mike Pence is a huge homophobe. He supports ex...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 3, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California AG pledges to defend birth control ...</td>\n",
       "      <td>SAN FRANCISCO (Reuters) - California Attorney ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>October 6, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZ RANCHERS Living On US-Mexico Border Destroy...</td>\n",
       "      <td>Twisted reasoning is all that comes from Pelos...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Apr 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   BREAKING: GOP Chairman Grassley Has Had Enoug...   \n",
       "1   Failed GOP Candidates Remembered In Hilarious...   \n",
       "2   Mike Pence’s New DC Neighbors Are HILARIOUSLY...   \n",
       "3  California AG pledges to defend birth control ...   \n",
       "4  AZ RANCHERS Living On US-Mexico Border Destroy...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  Donald Trump s White House is in chaos, and th...          News   \n",
       "1  Now that Donald Trump is the presumptive GOP n...          News   \n",
       "2  Mike Pence is a huge homophobe. He supports ex...          News   \n",
       "3  SAN FRANCISCO (Reuters) - California Attorney ...  politicsNews   \n",
       "4  Twisted reasoning is all that comes from Pelos...      politics   \n",
       "\n",
       "               date  target  \n",
       "0     July 21, 2017       1  \n",
       "1       May 7, 2016       1  \n",
       "2  December 3, 2016       1  \n",
       "3  October 6, 2017        0  \n",
       "4      Apr 25, 2017       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to tokenize and vectorize the data. We will use the Google News prettained Word2vec vectors, so download those via the nlpia package or directly from Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the nlpia package for downloading data too big for the repo\n",
    "\n",
    "BIG_URLS = {\n",
    "    'w2v': (\n",
    "        'https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz?dl=1',\n",
    "        1647046227,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are part of the nlpia package which can be pip installed and run from there.\n",
    "def dropbox_basename(url):\n",
    "    filename = os.path.basename(url)\n",
    "    match = re.findall(r'\\?dl=[0-9]$', filename)\n",
    "    if match:\n",
    "        return filename[:-len(match[0])]\n",
    "    return filename\n",
    "\n",
    "def download_file(url, data_path='.', filename=None, size=None, chunk_size=4096, verbose=True):\n",
    "    \"\"\"Uses stream=True and a reasonable chunk size to be able to download large (GB) files over https\"\"\"\n",
    "    if filename is None:\n",
    "        filename = dropbox_basename(url)\n",
    "    file_path = os.path.join(data_path, filename)\n",
    "    if url.endswith('?dl=0'):\n",
    "        url = url[:-1] + '1'  # noninteractive download\n",
    "    if verbose:\n",
    "        tqdm_prog = tqdm\n",
    "        print('requesting URL: {}'.format(url))\n",
    "    else:\n",
    "        tqdm_prog = no_tqdm\n",
    "    r = requests.get(url, stream=True, allow_redirects=True)\n",
    "    size = r.headers.get('Content-Length', None) if size is None else size\n",
    "    print('remote size: {}'.format(size))\n",
    "\n",
    "    stat = path_status(file_path)\n",
    "    print('local size: {}'.format(stat.get('size', None)))\n",
    "    if stat['type'] == 'file' and stat['size'] == size:  # TODO: check md5 or get the right size of remote file\n",
    "        r.close()\n",
    "        return file_path\n",
    "\n",
    "    print('Downloading to {}'.format(file_path))\n",
    "\n",
    "    with open(file_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            if chunk:  # filter out keep-alive chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "    r.close()\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting URL: https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz?dl=1\n",
      "remote size: 1647046227\n",
      "local size: 1647046227\n",
      "Downloading to ./GoogleNews-vectors-negative300.bin.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./GoogleNews-vectors-negative300.bin.gz'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file(BIG_URLS['w2v'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#from nlpia.loaders import get_data\n",
    "#word_vectors = get_data('w2v', limit=200000)\n",
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True, limit=200000)\n",
    "\n",
    "maxlen = 400\n",
    "\n",
    "def tokenize_and_vectorize(dataset):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    vectorized_data = []\n",
    "    expected = []\n",
    "    for i in range(len(dataset)):\n",
    "        tokens = tokenizer.tokenize(dataset.iloc[i,1])+tokenizer.tokenize(dataset.iloc[i,0])\n",
    "        sample_vecs = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                sample_vecs.append(word_vectors[token])\n",
    "\n",
    "            except KeyError:\n",
    "                pass  # No matching token in the Google w2v vocab\n",
    "            \n",
    "        vectorized_data.append(sample_vecs)\n",
    "\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our implementations of CNN, we want that the input have fixed length to pass into a feed forward layer for classification. A fixed length vector representation of an object is called an embedding. So that the thought vector is of consistent size, you have to unroll the net to a consistent number of time steps (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = tokenize_and_vectorize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(len(vectorized_data)*.8)\n",
    "\n",
    "x_train = vectorized_data[:split_point]\n",
    "y_train = dataset['target'][:split_point]\n",
    "x_test = vectorized_data[split_point:]\n",
    "y_test = dataset['target'][split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 400\n",
    "batch_size = 32         # How many samples to show the net before backpropogating the error and updating the weights\n",
    "embedding_dims = 300    # Length of the token vectors we will create for passing into the Convnet\n",
    "filters = 250           # Number of filters we will train\n",
    "kernel_size = 3         # The width of the filters, actual filters will each be a matrix of weights of size: embedding_dims x kernel_size or 300 x 3 in our case\n",
    "hidden_dims = 250       # Number of neurons in the plain feed forward net at the end of the chain\n",
    "epochs = 2              # Number of times we will pass the entire training dataset through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must manually pad/truncate\n",
    "\n",
    "def pad_trunc(data, maxlen):\n",
    "    \"\"\" For a given dataset pad with zero vectors or truncate to maxlen \"\"\"\n",
    "    new_data = []\n",
    "\n",
    "    # Create a vector of 0's the length of our word vectors\n",
    "    zero_vector = []\n",
    "    for _ in range(len(data[0][0])):\n",
    "        zero_vector.append(0.0)\n",
    "\n",
    "    for sample in data:\n",
    " \n",
    "        if len(sample) > maxlen:\n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample) < maxlen:\n",
    "            temp = sample\n",
    "            additional_elems = maxlen - len(sample)\n",
    "            for _ in range(additional_elems):\n",
    "                temp.append(zero_vector)\n",
    "        else:\n",
    "            temp = sample\n",
    "        new_data.append(temp)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can’t feed lists of integers into a neural network. You have to turn your lists into tensors. There are two ways to do that:\n",
    "* Pad your lists so that they all have the same length, turn them into an integer tensor of shape (samples, word_indices), and then use as the first layer in your network a layer capable of handling such integer tensors (the Embedding layer, which we’ll cover in detail later in the book).\n",
    "* One-hot encode your lists to turn them into vectors of 0s and 1s. This would mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vec- tor that would be all 0s except for indices 3 and 5, which would be 1s. Then you could use as the first layer in your network a Dense layer, capable of handling floating-point vector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_trunc(x_train, maxlen)\n",
    "x_test = pad_trunc(x_test, maxlen)\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), maxlen, embedding_dims))\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.reshape(x_test, (len(x_test), maxlen, embedding_dims))\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35918, 400, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 35918 samples, validate on 8980 samples\n",
      "Epoch 1/2\n",
      "35918/35918 [==============================] - 602s 17ms/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.0036 - val_accuracy: 0.9984\n",
      "Epoch 2/2\n",
      "35918/35918 [==============================] - 586s 16ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0071 - val_accuracy: 0.9980\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 input_shape=(maxlen, embedding_dims)))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "model_structure = model.to_json()\n",
    "with open(\"cnn_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "\n",
    "model.save_weights(\"cnn_weights.h5\")\n",
    "print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "with open(\"cnn_model.json\", \"r\") as json_file:\n",
    "    json_string = json_file.read()\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "model.load_weights('cnn_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(x_test)\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      1.00      1.00      4345\n",
      "    Not Fake       1.00      1.00      1.00      4635\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, target_names = ['Fake','Not Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEXCAYAAACqIS9uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdp0lEQVR4nO3de1yVVb7H8c8GBFRU0BSVkjQ8eMlL6ZSlHBO6qCOCkomNYBe1YrzNlI0kpZaoo9kFPaZmZd7LK2oeC2813qopLW9jmiVeQVRARUT23ucPpz1xjNDiYSPr+369fL141t77Wb8H67uX61l7bZvT6XQiIiLG8HB3ASIiUrYU/CIihlHwi4gYRsEvImIYBb+IiGEU/CIihlHwS7lit9t577336NmzJ1FRUXTt2pVJkyZRUFDwu875zDPP8NBDDzFv3rzrfv2uXbsYMmTIb+7//wsPD6d169ZcuHChSPvy5csJDQ1l7dq1v/r6c+fOER8fX+zjUVFR5ObmlkqtUjF5ubsAkZ8bPXo0OTk5vP/++1SrVo28vDyee+45Ro4cyaRJk37TOTMyMti8eTM7d+7E09Pzul/fokULUlJSflPfxQkICCAtLY3o6GhX2/Lly7nppptKfG1OTg67du0q9vHU1NRSqVEqLo34pdw4cuQIq1atYty4cVSrVg2AKlWqMGbMGB544AHgymj3ueeeo1u3bkRGRjJx4kQKCwuBKwE9ZcoUYmNjCQ8PZ/bs2Zw/f57+/ftTWFhIz549SU9PJzQ0lDNnzrj6/en4woULDBkyhKioKHr06EFSUhIOh4PPP/+cbt26/ab+i9O9e3dWrlzpOj527Bh5eXk0atTI1bZkyRJ69epFdHQ0nTp1YsGCBQAkJiaSn59PVFQUdrud22+/naFDh/LQQw+xa9cu1/VMnTqV3r17Y7fbOXXqFB06dGD79u2l8DclNzoFv5Qbe/fuJSQkBD8/vyLttWvX5sEHHwRg7Nix+Pv7s2rVKpYuXcr+/ft59913ASgoKCAgIIBFixaRkpLC5MmTqVSpEjNnzsTX15fU1FQaNGhQbP9paWlcuHCB1NRUlixZAlx5M/q56+3/0qVLv9hXx44d2bdvH5mZmcCVUfrPR/8XLlxg8eLFzJw5kxUrVvD666+7/sUzfvx41/V4enpy+fJlOnXqxMcff0yLFi1c53jmmWeoVKkS77zzDsOHD6dv3760a9eu5L8IqfAU/FJueHh44HA4fvU5n332GX379sVms+Ht7U1sbCyfffaZ6/GIiAgAmjdvTkFBAXl5edfcf5s2bTh48CBxcXHMnDmTfv36ERwcbEn/lSpVonPnzqxevRqANWvWuP5VAVC1alWmT5/Op59+yhtvvMH06dN/9Vratm17VZunpyeTJk3i7bffxmaz8dRTT13z70IqNgW/lBstW7bk0KFDnD9/vkh7RkYGAwcOJD8//6o3BofD4ZpqAfDx8QHAZrMBUNJWVD+/aXzLLbeQlpbGwIEDOX/+PI8//vhVN1pLs//o6GhWrlzJ119/TaNGjfD393c9dvLkSaKjozl27Bht2rRh2LBhv3odVapU+cX248eP4+Pjw+HDh3XDV1wU/FJuBAYGEhkZyQsvvOAK//PnzzN69Gj8/f3x9fWlQ4cOzJ8/H6fTSUFBAR9++CH33nvvdfVTs2ZN183RtLQ0V/uCBQtITEykQ4cODB8+nA4dOnDgwIEiry2N/n/SqlUr8vPzef311+nRo0eRx3bv3k3NmjVJSEggLCyMjRs3AldWKHl5eWG320t8U8vNzWX48OH8/e9/p1u3bowcOfI31SkVj4JfypVRo0YREhJCbGwsUVFR9OrVi5CQEMaOHQtAUlISZ86cITIyksjISBo2bMjTTz99XX0kJSXx8ssv06NHD/bu3Uvt2rWBKyNwu91O165d6dmzJ+fPn79q2WRp9P9zUVFR/PDDD4SFhRVpb9++PYGBgXTu3Jno6GhOnDhBzZo1OXz4MLVr16ZZs2Z06dKFs2fP/up13nfffbRv355BgwaRnp7O/Pnzf3OtUnHYtC2ziIhZNOIXETGMgl9ExDAKfhERwyj4RUQMo+AXETHMDbFJW+XwZHeXIPKLzn6itfFSfvkWk/Aa8YuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGMbL3QVI6Yhs/1/MGtGdwMhXqeTlwWuDH6J9i1sA+OSL73lh5gYcDie3N6pDyrDOVPH1xul0MuqdTXzyxfcATHg6gp4dm3LmXD4AB46cJu6V5W67JqnYnE4nL41MJKRxY/o9/iR2u51XJ45n65bN2AvtxD/+BI/07uPuMiskBX8FcFtQAOOfjsDDwwbAM9Ftqe1fhTZPzsTDZmP9m/E8fF9TPtywl3cTu/PK7M9YteU7mt1am01T+xEU/RqXCx20a34z8WOXs33PMTdfkVR0h77/nnFjx7Dr228IadwYgCUfLiL98GGWrlhN3oULxP2pN02bNqdFy5ZurrbiUfDf4Cr7ePHeC1H87a11zB4ZDUDKki+YtvyfOJ1Qy78KNfx8OZN7ZRR/z1PvYHc4AWhUP4Cc85ewO5x4V/KkVeO6DHukHQ3rB3Do2Fmen5bGkcxct12bVFyLFs4nqkdP6tWr72rbsH4dMb0ewcvLi+o1atC5yx/5aPVKBb8FLJ3jz8nJISkpifj4eM6ePUtiYiI5OTlWdmmcqX/tyqxVO9j1fWaR9kK7g1cGdGLPvAQyz15gy650AFfo75mXwKIxMUxetA2Hw0m9Wn5s2vEjL87ayN0DZvHFvmN8+EqvMr8eMcMLSS8R2T26SNvJkyeoW7ee6zgwsC4ZGSfLujQjWBr8L774Ii1atCA7O5uqVatSp04dhg8fbmWXRhnYvQ2Fdgdz1n7zi4+/+PZG6nWfzOGT2aQM61LkseZ9p9E8bhrP9bmHjncEc/hkDj0SP+DAkTMAvP7BdhrVDyC4bg3Lr0MEwPHvQcnPeXpo/YkVLP2tHj16lN69e+Ph4YG3tzd/+ctfOHlS7+ClJa5zS9qE1mP7zP6sGN+byt5ebJ/Zn3ua30zIzTWBKyP/uR9/S+vGdank5UGvTs2wXbkVwOGTOWz46gdah9Tl9kZ16PPA7UXOb7NBYaGjrC9LDFWvXj1OnTrlOs7MzCAwsK4bK6q4LA1+T09Pzp07h+3fSfPjjz/ioXfwUhOW8B5tn3ybdgNnEZ34ARcLCmk3cBYd77iViQkP4Olhw2aD2Ptv59MdP3K50MGoJzrySKfmANSr5UfHO27lH9+k43A4mTzoQdcIf2D3Nuw+lMmxrHPuvEQxyH3hEaxYtpTCwkJyc3NZ+78f0SnifneXVSFZenN38ODBxMXFceLECRISEti5cyfjxo2zsksBJi/ayqQ/P8gXswbgcDjZuvsIL87aCEDvl5bwxtDO/CX2HhxOJy9MX8/X350A4K9TPmFp8iN4enhw7FQu/caucOdliGEe6d2Ho+np9OoZReHlyzz8SG/a/uEud5dVIdmcTufVE2ul6MyZM3z77bfY7XZatWpF1apVqVy58nWdo3J4skXVifw+Zz8Z6e4SRIrlW8zQ3tJ5l1dffZWaNWty3333ERERwZ49e/jjH/9oZZciIlICS4M/PT2dCRMmkJWVxdChQ5k4cSITJkywsksRESmBpcH/xhtvkJubS0REBE2aNGHFihXcdZfm7ERE3MmSm7tTp051/VyvXj38/PzYu3cvM2bMAGDQoEFWdCsiItfA8i0bbDYbffpooyURkfLCkuAvbkTvdDo5evSoFV2KiMg1snTEP2/ePF577TUuXrzoarv55ptJS0uzslsREfkVlt7cfffdd0lNTaVr166kpaWRnJxMS+20JyLiVpYGf61atbjlllsIDQ3lu+++o2fPnvzwww9WdikiIiWwNPgrV67M9u3bCQ0NZePGjZw6dYrcXO3vLiLiTpYEf0ZGBnBlW+aNGzcSFhZGdnY2Xbp0oW/fvlZ0KSIi18iSm7tPP/00y5cvp3HjxgQGBuLh4cGUKVOs6EpERK6TJSP+n+/7tmrVKiu6EBGR38iS4P9p/30o+iYgIiLuZ/m3ovz8TUBERNzPkjn+AwcOEBERAVy50fvTz06nE5vNxvr1663oVkREroElwf/xxx9bcVoRESkFlgR/UFCQFacVEZFSoG8+FxExjIJfRMQwCn4REcMo+EVEDKPgFxExjIJfRMQwCn4REcMo+EVEDKPgFxExjIJfRMQwCn4REcMo+EVEDKPgFxExjIJfRMQwCn4REcMo+EVEDKPgFxExTLHfwDV27NhffWFSUlKpFyMiItYrNvj9/f3Lsg4RESkjxQb/oEGDin1RXl6eJcWIiIj1Svyy9XXr1pGSkkJeXh5OpxOHw0F2djY7duwoi/pERKSUlRj8EydOZNiwYSxcuJABAwawbt06qlatWha1iYiIBUpc1VO5cmW6du1K69at8fHxYfTo0Wzfvr0sahMREQuUGPze3t4UFBTQoEED9u3bh4eHBwUFBWVRm4iIWKDEqZ6IiAgGDhzIhAkTiI2N5auvvtKKHxGRG5jN6XQ6S3rS8ePHqV+/Pnv37uXLL7+kW7du1KpVqyzqA6ByeHKZ9SVyPc5+MtLdJYgUy7eYoX2JI/49e/YAcPbsWQDatm3LyZMnyzT4RUSk9JQY/IMHD3b9fPnyZbKysmjevDlLliyxtDAREbFGicG/YcOGIsc7d+5U6IuI3MCue5O21q1bu6Z/RETkxnPNc/wATqeT3bt3k5+fb2lRIiJinRJX9YSHh//nyTYbtWrV4tlnn+Xuu++2vLif5BeWWVci1yXgD8XvaSXibhd3TP3F9hJH/AsWLKBu3bpF2g4ePFg6VYmISJkrdo4/Ozub7OxsBg4cSE5ODtnZ2eTk5JCVlUVCQkJZ1igiIqWo2BH/s88+y5YtWwCKTOt4enrywAMPWF+ZiIhYotjgf+eddwBITExk/PjxZVaQiIhYq8TlnEOHDmX06NEAHDp0iISEBLKysqyuS0RELFJi8I8YMYJGjRoBEBQUxF133UViYqLlhYmIiDVKDP6zZ88SHx8PgI+PD4899hinTp2yvDAREbFGicFvt9vJyMhwHWdlZXENG3qKiEg5VeI6/scee4zo6GjCwsIA2LZtG88//7zlhYmIiDWuaT/+f/3rX2zfvh1PT09ycnL49NNPWbx4cVnUB+iTu1J+6ZO7Up795k/uAtSrV49Lly6xYMEC8vLyiIuLK9XiRESk7Pxq8B86dIjZs2ezatUqgoKCyM/PZ8OGDVSrVq2s6hMRkVJW7M3dAQMG0LdvX7y9vZkzZw6rV6+matWqCn0RkRtcscG/b98+mjVrRuPGjbn11luBK7tziojIja3Y4N+0aRMxMTGsXr2aDh06MGTIEC5dulSWtYmIiAWKDX4vLy+6dOnC3LlzWbp0KXXq1CE/P58HH3yQhQsXlmWNIiJSiq5pOedPLl68yMqVK1m0aBHLly+3sq4itJxTyist55TyrLjlnNcV/O6i4JfySsEv5VlxwX/dX7YuIiI3NgW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIoZR8IuIGEbBLyJiGAW/iIhhFPwiIobxcncBUnbWr0vjrf9JwcPmQbXq1Rn9cjK3NGjg7rKkgou8ryWzXokjMGw4ANERrRn+xIP4eHuRfuIM/V+cy5mcC9wU4MfUkbE0uqU2Xl4erP3HHka+mUpow0Bmj3vMdT5PDw9ub1yf2GffJnXDN266qhubzel0Ot1dREnyC91dwY0vPz+fjh3asXhpKg2Cg5n7/mw+376VqW/NdHdpN7SAPwxydwnl2m0NapM6JYHAm6pTu/2z3NmsAUveeIr7+k0m/cQZJj7bE19fb4YkL+LdsfEcPn6GMdNW4+Ptxeq3BjF35XbmpG4vcs4Jf+1B3Ztq8NgLs91zUTeQizum/mK7RvyGcNjt4HRy/vw5APLyLuDt7ePmqqQiq+xbiffG9uNvry1zjdj7dP0D76/YRvqJMwCMnbGGmjWqArBy47ds2/k9AJcKCtlz8DgN6tUscs72d9xGj/vvoG2vcWV3IRWQpcGfl5dHeno6oaGhXLx4kSpVqljZnfyKKlWrkvTSGOL/FIu/vz92h4P35y50d1lSgU0d2YdZSzez67tjrraQ4DrsPnCMD18fSHD9muw5cJznJy8DYMX6na7ntQq9md5d2vJQ/zeLnHP8X3owauoqzl3IL5uLqKAsu7m7bds2oqKiSEhI4NSpU4SHh7N582arupMSHPhuPzPe+h+Wr1zDuk2b6T/waZ4dNpgbYKZPbkADe4VRaHdcNU1TycuTrv/dgsFjF9Iu9u9knD7HtBf7FHnO/fc0ZdVbf+avf1/Mtz9702jXqiG1/Kvywf/+s0yuoSKzLPhfe+01FixYQPXq1alTpw7z5s1j4sSJVnUnJdi6ZTOt77jTdTM3ts+fOHjwANnZZ91cmVREcd3vpk3zBmxfNIIVU5+hsk8lti8aAcC6bfvIOH0Op9PJnNRt3NWyoet1Q/qG887YePolzmbhR18WOefDD97J/NVfaLBSCiwLfofDQe3atV3HISEhVnUl16BJ02Z89c8vOZ2VBcDG9esICrqZgICaJbxS5PqFxb1K217jaBc7gehBb3Hx0mXaxU5g2sJNdO7Q3DWvHxXRmq/2pANXQv+pR8LoGP8qGz/ff9U5O7RpzKYvrm6X62fZHH/dunXZuHEjNpuN3Nxc5s+fT/369a3qTkpwd7t76Pf4kzz5eByVvCpRvUYN3pg6zd1liWHWfLaboEB/Ppk1FA8PG+knzvDMmAVU8vLkpYQ/knPuIosmD3A9f1naDia+8zEAIQ1qc/j4GXeVXqFYtpzz9OnTJCcns3XrVhwOB+3atSMpKYk6depc97m0nFPKKy3nlPKsuOWcWscv8jso+KU8K/N1/OHh4dhstqva169fb1WXIiJyDSwL/rlz57p+LiwsJC0tjYKCAqu6ExGRa2TZqp6goCDXn+DgYPr378+6deus6k5ERK6RZSP+L7/8zxpcp9PJgQMHuHTpklXdiYjINbIs+FNSUlw/22w2AgICmDBhglXdiYjINbIs+Lt06cKjjz5q1elFROQ3smyOf8GCBVadWkREfgdLP7kbHx9Pq1at8PH5z/a/gwZp3bOIiDuV+oh/+fLlALRu3Zq77rqrSOiLiIj7lfond3v06OEK/9KiT+5KeaVP7kp5Vtwnd/Vl6yIihin1Of4DBw4QERFxVbvT6cRms2nLBhERNyv14A8ODmbmTH2Bt4hIeVXqwV+pUiWCgoJK+7QiIlJKSn2O/8477yztU4qISCnSfvwiv4NW9Uh5plU9IiICKPhFRIyj4BcRMYyCX0TEMAp+ERHDKPhFRAyj4BcRMYyCX0TEMAp+ERHDKPhFRAyj4BcRMYyCX0TEMAp+ERHDKPhFRAyj4BcRMYyCX0TEMAp+ERHDKPhFRAyj4BcRMYyCX0TEMAp+ERHDKPhFRAyj4BcRMYyCX0TEMAp+ERHDKPhFRAyj4BcRMYyCX0TEMAp+ERHDKPhFRAyj4BcRMYyCX0TEMAp+ERHD2JxOp9PdRYiISNnRiF9ExDAKfhERwyj4RUQMo+AXETGMgl9ExDAKfhERwyj4RUQMo+AXETGMgl9ExDBe7i5Afr+jR4/SuXNnbrvttiLt06dPp169elc9f8qUKQAMHjy4TOoTs40ZM4avv/6ay5cvk56e7vrvND4+npiYGDdXZyYFfwVRp04dUlNT3V2GyFVGjRoFXBmgxMfH67/TckBTPRXYd999R1xcHDExMXTq1Ik5c+YUedxutzNkyBAmTpwIwGeffcbDDz9MdHQ0gwYN4uzZs+4oWwwxZcoUnnzySbp27cr8+fOJi4vj888/B668SYSHhwOQlZVFQkICPXv2JCYmhq1bt7qz7ApBI/4KIjMzk6ioKNdxZGQkGRkZJCQkcM8993DkyBG6d+9OfHw8AE6nk6SkJOrWrcvzzz/PmTNnmDx5MnPmzKFGjRosWrSIV199leTkZHddkhigoKCANWvWALB27dpffE5ycjIxMTFERESQmZnJo48+yooVK/Dz8yvLUisUBX8F8UtTPXa7nX/84x/MmDGD/fv3k5eX53ps0aJFnDt3jvXr1wPwzTffcOLECdcbg8PhoEaNGmV3AWKkli1blvicrVu3cujQIVJSUgAoLCzkyJEjNG3a1OryKiwFfwU2bNgwqlevTqdOnejatSsfffSR67E77riDZs2aMXbsWFJSUrDb7dx5551Mnz4dgEuXLnHhwgV3lS6G8PX1LXL80y7xhYWFrjaHw8H777+Pv78/ABkZGdx0001lV2QFpDn+CmzLli0MGTKE+++/ny+//BK48q8AgCZNmjBgwAAOHDjAxo0badWqFTt37uSHH34AYNq0aa65f5GyEBAQwMGDBwFYt26dq71du3YsWLAAgIMHD9K9e3cuXrzolhorCo34K7DBgwfz6KOPUr16dRo2bEhQUBBHjx51Pe7t7c3o0aMZMWIEq1evZty4cQwbNgyHw0FgYCCTJk1yY/Vimv79+zNixAiWLl1KRESEqz0pKYmXXnqJyMhIACZOnKj5/d9J38AlImIYTfWIiBhGwS8iYhgFv4iIYRT8IiKGUfCLiBhGwS8V2tGjR2natClRUVGuP927d2fJkiW/67xPPfUUy5YtAyAqKorc3Nxin3vu3DnXJ6Kvx9q1a4mLi/vNNYoUR+v4pcLz9fUtsp1FRkYG3bp14/bbb6dJkya/+/wl7TaZk5PDrl27fnc/IqVFwS/GCQwMJDg4mC1btvDyyy9z8eJF/Pz8mDt3LosXL2bhwoU4HA78/f158cUXue2228jIyGDEiBFkZmZSv359Tp8+7TpfaGgo27Zto2bNmsyYMYPly5fj5eVFcHAwEyZMIDExkfz8fKKioli2bBk//vgjycnJZGdnY7fbiYuL4+GHHwbgzTffZNWqVfj7+xMcHOyuX5FUcAp+Mc6OHTtIT08nPz+fgwcPsmHDBvz8/Pjiiy9YsWIF8+fPp3LlymzevJnBgwezZs0aXn75ZVq1asWwYcM4fPgw0dHRV513/fr1LFu2jA8//JAaNWowfvx45s2bx/jx44mMjCQ1NZXCwkLXVtjNmzfn3Llz9O7dm5CQELKysvjkk09YsWIFvr6+/PnPf3bDb0dMoOCXCu+n0TZc2asoICCASZMmcfr0aUJDQ10f/9+0aROHDx8mNjbW9dqcnByys7PZunUrf/vb3wAIDg7m7rvvvqqfbdu20blzZ9eupomJiQBFtsn48ccfSU9P54UXXihS3969e/n+++954IEHXPXExMQwd+7c0vxViAAKfjHA/5/j/8myZcuoUqWK69jhcBAVFcXw4cNdx5mZmdSoUQObzcbPdzfx8rr6fx1PT09sNpvrODc396qbvna7nerVqxepJysri2rVqjFp0qQifXh6ev6GqxUpmVb1iPxb+/bt+eijj8jMzARg4cKF9OvXD4CwsDA++OADAI4fP+76pqifu/fee0lLS+P8+fPAlW+Ymj17Nl5eXtjtdpxOJw0bNsTHx8cV/CdOnKBbt27s3r2bsLAw1q5dS25uLg6HQ19RKJbRiF/k38LCwhgwYABPPPEENpsNPz8/pk6dis1mY9SoUSQmJtKlSxfq1q37i6uBOnbsyMGDB+nTpw8AISEhvPLKK1SuXJlmzZrRpUsXFi5cyLRp00hOTmbWrFkUFhYydOhQ2rRpA8D+/fuJiYmhevXqNGnSRF9/KZbQ7pwiIobRVI+IiGEU/CIihlHwi4gYRsEvImIYBb+IiGEU/CIihlHwi4gYRsEvImKY/wNIe3kDAIyhsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm, xticklabels = ['Fake','True'] , yticklabels = ['Fake','True'], annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AUC) score for Logistic Regression Classifier: 0.9980\n"
     ]
    }
   ],
   "source": [
    "print('(AUC) score for Logistic Regression Classifier: {:.4f}'.format(roc_auc_score(y_test, pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
